<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>mcfeedback — Iteration 14: 012b + hidden cluster</title>
<style>
  body { font-family: 'Segoe UI', system-ui, sans-serif; background: #0f0f13; color: #e0e0e0; max-width: 960px; margin: 0 auto; padding: 2rem; }
  h1 { color: #7eb8f7; font-size: 1.4rem; border-bottom: 1px solid #2a2a3a; padding-bottom: 0.5rem; }
  h2 { color: #a0c4ff; font-size: 1.1rem; margin-top: 2rem; }
  h3 { color: #c0d8ff; font-size: 0.95rem; margin-top: 1.5rem; }
  pre { background: #16161e; border: 1px solid #2a2a3a; border-radius: 6px; padding: 1rem; overflow-x: auto; font-size: 0.82rem; line-height: 1.5; }
  table { border-collapse: collapse; width: 100%; margin: 1rem 0; font-size: 0.88rem; }
  th { background: #1e1e2e; color: #a0c4ff; padding: 0.5rem 0.8rem; text-align: left; border-bottom: 2px solid #3a3a5a; }
  td { padding: 0.45rem 0.8rem; border-bottom: 1px solid #1e1e2e; }
  tr:hover td { background: #1a1a28; }
  .good { color: #6fcf97; }
  .bad { color: #eb5757; }
  .neutral { color: #b0b0c0; }
  .highlight { color: #f6c90e; font-weight: bold; }
  .tag { display: inline-block; padding: 0.15rem 0.5rem; border-radius: 4px; font-size: 0.78rem; font-weight: bold; }
  .tag-new { background: #1b3a4a; color: #7eb8f7; }
  .tag-same { background: #2a2a1b; color: #f6c90e; }
  .verdict { background: #1a1a28; border-left: 4px solid #7eb8f7; padding: 1rem 1.2rem; border-radius: 0 6px 6px 0; margin: 1.5rem 0; }
  .verdict h3 { color: #7eb8f7; margin-top: 0; }
  .topo-box { background: #16161e; border: 1px solid #2a2a3a; border-radius: 6px; padding: 1rem 1.2rem; margin: 1rem 0; font-family: monospace; font-size: 0.85rem; }
  .topo-input  { color: #6fcf97; }
  .topo-hidden { color: #f6c90e; }
  .topo-output { color: #7eb8f7; }
  .topo-mod    { color: #c084fc; }
  .comparison-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; margin: 1rem 0; }
  .cg-cell { background: #16161e; border: 1px solid #2a2a3a; border-radius: 6px; padding: 0.8rem; }
  .cg-label { font-size: 0.75rem; color: #808098; text-transform: uppercase; letter-spacing: 0.05em; }
  .cg-value { font-size: 1.5rem; font-weight: bold; margin: 0.3rem 0 0; }
  code { background: #16161e; border: 1px solid #2a2a3a; border-radius: 3px; padding: 0.1rem 0.3rem; font-size: 0.82rem; }
</style>
</head>
<body>

<h1>mcfeedback — Iteration 14: 012b + hidden cluster</h1>

<p>
  <span class="tag tag-new">NEW: HIDDEN CLUSTER</span>
  &nbsp;Base: experiment-012b (exp-004 + weightDecay=0.0025). One addition: a third cluster of 20
  neurons (all regular, no clamped inputs, no output neurons) acting as an intermediate hidden layer.
  10 seeds × 1000 episodes × 4 conditions.
</p>

<h2>Topology</h2>

<div class="topo-box">
<pre style="margin:0;padding:0;border:none;background:none;">
  cluster_0  [x=0]   <span class="topo-mod">■■</span> <span class="topo-input">●●●●●</span> ○○○○○○○○○○○○○○○○○○○○○○○   30 neurons
                      mod   input (5)        regular hidden (23)

  cluster_1  [x=10]  <span class="topo-mod">■■</span> ○○○○○○○○○○○○○○○○○○○○○○○ <span class="topo-output">●●●●●</span>   30 neurons
                      mod        regular hidden (23)       output (5)

  cluster_2  [x=20]  <span class="topo-mod">■■</span> ○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○   20 neurons  ← NEW
                      mod                regular hidden (18)

  Total:  80 neurons  (60 in 012b)   2867 synapses
  <span class="topo-input">●</span> input (5)   <span class="topo-output">●</span> output (5)   ○ regular hidden (64)   <span class="topo-mod">■</span> modulatory (6)</pre>
</div>

<p>
  All clusters connect to each other with <code>interClusterConnectionProb: 0.5</code>.
  The hidden cluster (cluster_2) receives signals from both cluster_0 and cluster_1 and
  sends signals back to both — it is fully recurrent with the rest of the network.
</p>

<h2>Config</h2>
<pre>clustersCount:           3       ← new (cluster_2 = hidden)
hiddenNeuronsPerCluster: 20      ← new (moderate size)
neuronsPerCluster:       30      (cluster_0 and cluster_1, unchanged)
learningRate:            0.01    (exp-004 original)
weightDecay:             0.0025  (012b fix)
flagStrengthGain:        0.3
flagDecayRate:           0.7
flagStrengthThreshold:   0.5
reward:                  linear  (no squaring, no annealing)

No direction-consistent flags, no frustration flip, no propagationCycles.</pre>

<h2>Results</h2>

<div class="comparison-grid">
  <div class="cg-cell">
    <div class="cg-label">012b baseline (no hidden)</div>
    <div class="cg-value good">55.0%</div>
    <div style="color:#808098;font-size:0.82rem;">10/10 seeds · std 0% · |w| 0.79</div>
  </div>
  <div class="cg-cell">
    <div class="cg-label">014 Full model (+ hidden cluster)</div>
    <div class="cg-value highlight">54.0%</div>
    <div style="color:#808098;font-size:0.82rem;">9/10 seeds · std 3.2% · |w| 0.84</div>
  </div>
</div>

<h2>Distribution (frozen-weight accuracy)</h2>
<table>
  <tr><th>Condition</th><th>Mean</th><th>Std</th><th>Min</th><th>Max</th><th>All seeds</th></tr>
  <tr>
    <td>Baseline</td>
    <td>54.0%</td><td>3.2%</td><td class="bad">45%</td><td class="good">55%</td>
    <td class="neutral">55 55 55 55 55 55 55 55 55 45</td>
  </tr>
  <tr>
    <td>Ambient only</td>
    <td>53.0%</td><td>6.3%</td><td class="bad">35%</td><td class="good">55%</td>
    <td class="neutral">55 55 55 55 55 55 55 35 55 55</td>
  </tr>
  <tr>
    <td>Dampening only</td>
    <td class="good">55.0%</td><td class="good">0.0%</td><td class="good">55%</td><td class="good">55%</td>
    <td class="neutral">55 55 55 55 55 55 55 55 55 55</td>
  </tr>
  <tr>
    <td>Full model</td>
    <td>54.0%</td><td>3.2%</td><td class="bad">45%</td><td class="good">55%</td>
    <td class="neutral">55 45 55 55 55 55 55 55 55 55</td>
  </tr>
</table>

<h2>Paired t-tests vs Baseline</h2>
<table>
  <tr><th>Comparison</th><th>Mean diff</th><th>t</th><th>p</th><th>Significant?</th></tr>
  <tr><td>Ambient only vs Baseline</td><td>−1.0%</td><td>−0.4286</td><td>0.5005</td><td class="neutral">ns</td></tr>
  <tr><td>Dampening only vs Baseline</td><td>+1.0%</td><td>1.0000</td><td>0.2534</td><td class="neutral">ns</td></tr>
  <tr><td>Full model vs Baseline</td><td>+0.0%</td><td>0.0000</td><td>1.0000</td><td class="neutral">ns</td></tr>
</table>

<h2>Per-pattern mean accuracy (across seeds)</h2>
<table>
  <tr><th>Condition</th><th>P1</th><th>P2</th><th>P3</th><th>P4</th></tr>
  <tr><td>Baseline</td><td>42.0%</td><td>56.0%</td><td>62.0%</td><td>56.0%</td></tr>
  <tr><td>Ambient only</td><td>42.0%</td><td>58.0%</td><td>56.0%</td><td>56.0%</td></tr>
  <tr><td>Dampening only</td><td class="bad">40.0%</td><td class="good">60.0%</td><td class="good">60.0%</td><td class="good">60.0%</td></tr>
  <tr><td>Full model</td><td>42.0%</td><td>58.0%</td><td>58.0%</td><td>58.0%</td></tr>
</table>
<p style="color:#808098;font-size:0.85rem;">
  P1=[1,0,1,0,1]→[0,1,0,1,0] &nbsp;·&nbsp;
  P2=[1,1,0,0,0]→[0,0,1,1,1] &nbsp;·&nbsp;
  P3=[1,0,0,0,1]→[0,1,1,1,0] &nbsp;·&nbsp;
  P4=[0,1,0,1,0]→[1,0,1,0,1]
</p>
<p>
  P1 accuracy remains near 40% across all conditions. The (40+60+60+60)/4 = <strong>55% attractor</strong>
  persists. The hidden cluster does not help the network distinguish P1 from P4.
</p>

<h2>Mean |weight| — Full model</h2>
<table>
  <tr><th>Seed</th><th>Accuracy</th><th>Mean |weight|</th><th>Note</th></tr>
  <tr><td>42</td><td class="good">55%</td><td>1.0042</td><td class="neutral">high |w|</td></tr>
  <tr><td>137</td><td class="bad">45%</td><td>0.6791</td><td class="bad">stuck — lower |w|</td></tr>
  <tr><td>271</td><td class="good">55%</td><td>0.8593</td><td></td></tr>
  <tr><td>314</td><td class="good">55%</td><td>0.8518</td><td></td></tr>
  <tr><td>500</td><td class="good">55%</td><td>0.8721</td><td></td></tr>
  <tr><td>618</td><td class="good">55%</td><td>0.8456</td><td></td></tr>
  <tr><td>777</td><td class="good">55%</td><td>0.8258</td><td></td></tr>
  <tr><td>888</td><td class="good">55%</td><td>0.8812</td><td></td></tr>
  <tr><td>999</td><td class="good">55%</td><td>0.8064</td><td></td></tr>
  <tr><td>1234</td><td class="good">55%</td><td>0.8214</td><td class="good">recovered (was 0.29 in exp-013)</td></tr>
</table>
<table>
  <tr><th>Group</th><th>Seeds</th><th>Mean |weight|</th></tr>
  <tr><td class="good">Good (≥55%)</td><td class="good">9/10</td><td>0.8631</td></tr>
  <tr><td class="bad">Poor (&lt;55%)</td><td class="bad">1/10</td><td>0.6791</td></tr>
</table>
<p style="color:#808098;font-size:0.85rem;">
  Mean |weight| is higher than 012b (0.84 vs 0.79) — the hidden cluster creates more synaptic pathways
  for chemical diffusion to strengthen. Seed 1234 which was weight-starved in exp-013 now recovers
  fully; only seed 137 remains stuck.
</p>

<h2>Summary: 012b vs 014</h2>
<table>
  <tr><th></th><th>012b (2 clusters)</th><th>014 (3 clusters, hidden)</th></tr>
  <tr><td>Topology</td><td>60 neurons · 2 clusters</td><td>80 neurons · 3 clusters</td></tr>
  <tr><td>Synapses</td><td>~1800</td><td>2867</td></tr>
  <tr><td>Mean accuracy (Full)</td><td class="good">55.0%</td><td>54.0%</td></tr>
  <tr><td>Std</td><td class="good">0.0%</td><td>3.2%</td></tr>
  <tr><td>Seeds ≥ 55%</td><td class="good">10/10</td><td>9/10</td></tr>
  <tr><td>Mean |weight|</td><td>0.7898</td><td class="good">0.8447</td></tr>
  <tr><td>Dampening-only</td><td class="good">10/10 @ 55%</td><td class="good">10/10 @ 55%</td></tr>
</table>

<div class="verdict">
  <h3>Verdict</h3>
  <p>
    The hidden cluster <strong>does not break the 55% ceiling.</strong> The per-pattern breakdown is
    identical to 012b — P1 stays near 40%, P2/P3/P4 stay near 60%. The network finds the same
    attractor regardless of whether a hidden cluster is available.
  </p>
  <p>
    The hidden cluster adds representational capacity but the learning rule cannot exploit it for
    this task. The 55% attractor is a <strong>task-structural trap</strong>, not a capacity limitation:
    P1=[1,0,1,0,1] and P4=[0,1,0,1,0] are exact complements, and the reward signal (linear accuracy)
    does not penalise the network strongly enough for failing P1 while succeeding at P2/P3/P4.
  </p>
  <p>
    The hidden cluster does raise mean |weight| slightly (0.84 vs 0.79), suggesting more active synaptic
    pathways. Seed 1234 which was weight-starved in exp-013 recovers here. Only seed 137 remains stuck (9/10).
  </p>
  <p>
    <strong>What would actually break the ceiling?</strong>
  </p>
  <ul>
    <li><strong>Curriculum weighting</strong> — present P1 more frequently or weight its loss higher,
    forcing the network to attend to the failing pattern.</li>
    <li><strong>More training episodes</strong> (2000–5000) — if the ceiling is a convergence-speed
    limit, not structural.</li>
    <li><strong>Stronger negative reward</strong> — current reward is symmetric (±1). Increasing the
    penalty for wrong outputs may push past the 45% P1 sub-attractor.</li>
    <li><strong>Larger hidden cluster</strong> — though capacity appears not to be the bottleneck,
    a much larger hidden layer (e.g., 50+ neurons) could be tested.</li>
  </ul>
  <p>
    <strong>Current best overall: experiment-012b</strong> — 10/10 seeds, 55.0% mean, std 0%.
  </p>
</div>

<p style="color:#505060;font-size:0.78rem;margin-top:3rem;">
  Generated 2026-02-22 · mcfeedback experiment-014 · 10 seeds × 1000 episodes × 4 conditions · 80 neurons · 2867 synapses
</p>

</body>
</html>
